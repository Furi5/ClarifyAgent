# Deep Research Agent 流程设计与澄清边界讨论

## 当前流程分析

### 现状
1. **用户输入** → Planner 分析 → 返回 `CONFIRM_PLAN`
2. **展示计划** → 等待用户确认
3. **用户确认** → 系统说"可以开始研究"，但**没有真正执行检索**

### 问题
- ❌ 没有判断信息是否足够的机制
- ❌ 确认后没有真正开始检索
- ❌ 所有情况都走 CONFIRM_PLAN，没有区分"足够"和"不够"

---

## 目标流程设计

### 核心思路
```
用户输入 → 判断信息充分性 → 分支：
  ├─ 信息足够 → 直接开始检索并返回结果
  └─ 信息不够 → 澄清问题，直到足够
```

---

## 一、如何判断"信息是否足够"？

### 1.1 信息充分性的判断维度

#### A. 研究主题明确性
- ✅ **足够**：有明确的研究对象（如"KRAS G12C 靶点"、"GLP-1 激动剂"）
- ❌ **不够**：模糊或缺失（如"帮我研究一下"、"那个靶点"）

#### B. 研究范围可推断性
- ✅ **足够**：可以从主题推断出研究重点（如"KRAS G12C" → 可推断靶点验证、药物、临床进展）
- ❌ **不够**：主题太宽泛，无法确定重点（如"癌症"、"药物"）

#### C. 研究目标清晰度
- ✅ **足够**：有明确的研究目标（如"最新进展"、"耐药机制"、"临床数据"）
- ❌ **不够**：目标不明确（如"了解一下"、"有什么信息"）

#### D. 关键术语理解度
- ✅ **足够**：所有关键术语都能理解（如基因名、药物名、技术术语）
- ❌ **不够**：有不认识的术语需要验证（触发 `VERIFY_TOPIC`）

### 1.2 判断标准（建议）

使用 `confidence` 分数 + 关键维度检查：

```python
信息足够 = (
    confidence >= 0.7 AND
    研究主题明确 AND
    研究范围可推断 AND
    研究目标清晰 AND
    无未知术语
)
```

**示例判断：**

| 用户输入 | 信息足够？ | 原因 |
|---------|----------|------|
| "KRAS G12C 靶点" | ✅ 足够 | 主题明确，可推断研究重点 |
| "帮我研究一下" | ❌ 不够 | 主题缺失 |
| "那个新药" | ❌ 不够 | 主题不明确 |
| "STATUS6 基因" | ⚠️ 先验证 | 术语可能未知，需 VERIFY_TOPIC |
| "GLP-1 激动剂最新进展" | ✅ 足够 | 主题明确，目标清晰 |
| "癌症治疗" | ❌ 不够 | 范围太宽泛 |

---

## 二、澄清的边界

### 2.1 什么情况下需要澄清？

#### 必须澄清的情况（硬边界）

1. **主题缺失或模糊**
   - ❌ "帮我研究一下"
   - ❌ "那个东西"
   - ✅ 澄清："请告诉我具体的研究主题是什么？"

2. **范围过于宽泛**
   - ❌ "癌症"
   - ❌ "药物"
   - ✅ 澄清："您想研究癌症的哪个方面？比如特定类型、靶点、治疗策略等"

3. **目标不明确**
   - ❌ "了解一下"
   - ❌ "有什么信息"
   - ✅ 澄清："您希望了解什么？比如最新进展、机制、临床数据等"

4. **关键术语未知且无法推断**
   - ❌ "XYZ123 基因"（如果确实不存在或无法推断）
   - ✅ 先 VERIFY_TOPIC，如果确认不存在，再澄清

#### 不需要澄清的情况（可推断）

1. **主题明确，范围可推断**
   - ✅ "KRAS G12C 靶点" → 可推断研究重点
   - ✅ "ADC 药物的 linker 设计" → 可推断研究方向

2. **有合理假设空间**
   - ✅ "GLP-1 激动剂" → 可假设关注最新进展、临床数据
   - ✅ "PD-1 耐药机制" → 可假设关注机制分类、生物标志物

3. **术语可通过上下文推断**
   - ✅ "那个靶点"（如果上下文有提到）→ 可推断

### 2.2 澄清的原则

#### 原则 1：最小化澄清
- 能推断的就不问
- 有合理假设的就先假设，让用户确认

#### 原则 2：一次澄清一个关键点
- 不要一次问多个问题
- 聚焦最关键的信息缺失

#### 原则 3：提供选项而非开放问题
- ❌ "您想研究什么？"
- ✅ "您想研究 KRAS G12C 的哪个方面？A) 靶点验证 B) 已上市药物 C) 临床进展"

---

## 三、改进方案设计

### 3.1 新增 Action：`START_RESEARCH`

```python
NextAction = Literal[
    "START_RESEARCH",    # 🆕 信息足够，直接开始检索
    "NEED_CLARIFICATION", # 🆕 信息不够，需要澄清
    "VERIFY_TOPIC",      # 术语未知，先验证
    "CONFIRM_PLAN",      # 信息足够但需要确认计划（可选，用于高价值任务）
    "CANNOT_DO",         # 无法处理
]
```

### 3.2 判断逻辑

```python
def should_start_research(plan: Plan) -> bool:
    """判断是否可以直接开始研究"""
    return (
        plan.confidence >= 0.7 and
        plan.task.goal and  # 有明确目标
        len(plan.task.research_focus) >= 3 and  # 有足够的研究重点
        plan.next_action != "VERIFY_TOPIC"  # 没有未知术语
    )

def needs_clarification(plan: Plan) -> bool:
    """判断是否需要澄清"""
    return (
        plan.confidence < 0.5 or  # 置信度低
        not plan.task.goal or  # 目标缺失
        len(plan.task.research_focus) < 2  # 研究重点太少
    )
```

### 3.3 流程设计

```
用户输入
  ↓
Planner 分析
  ↓
判断信息充分性
  ├─ confidence >= 0.7 AND 信息完整
  │   └─ START_RESEARCH → 直接检索并返回结果
  │
  ├─ confidence < 0.5 OR 信息不完整
  │   └─ NEED_CLARIFICATION → 澄清问题
  │
  ├─ 有未知术语
  │   └─ VERIFY_TOPIC → 先搜索验证
  │
  └─ confidence >= 0.7 BUT 高价值任务
      └─ CONFIRM_PLAN → 展示计划，用户确认后 START_RESEARCH
```

### 3.4 澄清问题的设计

```python
class ClarificationQuestion(BaseModel):
    question: str  # 澄清问题
    options: Optional[List[str]] = None  # 可选项（如果有）
    missing_info: str  # 缺失的信息类型
```

**示例：**

```json
{
  "next_action": "NEED_CLARIFICATION",
  "clarification": {
    "question": "您想研究 KRAS G12C 的哪个方面？",
    "options": [
      "靶点验证证据",
      "已上市/在研抑制剂",
      "临床管线进展",
      "耐药机制"
    ],
    "missing_info": "研究重点"
  }
}
```

---

## 四、普适性设计考虑

### 4.1 领域无关性

当前设计已经比较普适：
- ✅ 不依赖特定领域知识（如 SMILES、靶点）
- ✅ 基于通用研究模式（主题、重点、目标）
- ✅ 可适用于任何研究领域

### 4.2 可扩展性

1. **研究重点推断规则**
   - 当前：基于领域知识推断
   - 可扩展：支持用户自定义规则或模板

2. **澄清问题模板**
   - 当前：动态生成
   - 可扩展：支持预定义模板库

3. **检索策略**
   - 当前：基于 research_focus 生成查询
   - 可扩展：支持多种检索策略（学术、专利、新闻等）

### 4.3 边界情况处理

1. **用户拒绝澄清**
   - 提供默认假设，继续执行

2. **澄清后仍不清晰**
   - 设置最大澄清次数（如 3 次），超过后使用最佳猜测

3. **用户修改计划**
   - 支持在确认后修改 research_focus

---

## 五、实施建议

### 阶段 1：基础实现
1. 添加 `START_RESEARCH` 和 `NEED_CLARIFICATION` action
2. 实现信息充分性判断逻辑
3. 实现直接检索功能

### 阶段 2：优化
1. 优化澄清问题的生成质量
2. 支持多轮澄清
3. 优化检索结果的组织和展示

### 阶段 3：增强
1. 支持用户自定义研究重点
2. 支持检索策略选择
3. 支持结果导出和后续处理

---

## 六、关键决策点

### Q1: CONFIRM_PLAN 是否还需要？
**建议：保留，但仅用于高价值/复杂任务**
- 简单任务：直接 START_RESEARCH
- 复杂任务：CONFIRM_PLAN → 用户确认 → START_RESEARCH

### Q2: 澄清的粒度？
**建议：一次澄清一个关键点**
- 避免信息过载
- 保持对话流畅

### Q3: confidence 阈值？
**建议：0.7**
- 低于 0.7：必须澄清
- 0.7-0.9：可选择性确认
- 高于 0.9：直接开始

### Q4: 如何生成检索查询？
**建议：基于 research_focus 生成多个查询**
- 每个 research_focus 对应一个查询
- 合并结果，按重点组织

---

## 总结

**核心改进：**
1. ✅ 添加信息充分性判断
2. ✅ 信息足够时直接开始检索
3. ✅ 信息不够时精准澄清
4. ✅ 保持普适性和可扩展性

**关键原则：**
- 最小化澄清，最大化推断
- 一次澄清一个关键点
- 提供选项而非开放问题
- 保持流程简洁高效
