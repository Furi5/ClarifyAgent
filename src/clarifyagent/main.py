import asyncio

from .agent import build_model
from .config import (
    CLARIFIER_MODEL, PLANNER_MODEL, EXECUTOR_MODEL, SYNTHESIZER_MODEL,
    MAX_PARALLEL_SUBAGENTS
)
from .dialog import SessionState, add_user, add_assistant, update_task_draft
from .orchestrator import Orchestrator
from .schema import ResearchResult
from typing import Optional


def render_plan(plan) -> str:
    """Render plan for display."""
    task = plan.task
    lines = [f"æˆ‘ç†è§£ä½ æƒ³åšï¼š**{task.goal}**", ""]
    
    # if getattr(task, "research_focus", None):
    # if task.research_focus:
        # lines.append("è®¡åˆ’é‡ç‚¹è¦†ç›–ï¼š")
        # for f in task.research_focus:
        #     lines.append(f"â€¢ {f}")
        # lines.append("")
    
    # if getattr(plan, "assumptions", None):
    # if plan.assumptions:
    #     lines.append("ï¼ˆæˆ‘çš„å‡è®¾ï¼š" + "ï¼›".join(plan.assumptions) + "ï¼‰")
    #     lines.append("")
    
    lines.append(plan.confirm_prompt or "è¿™æ ·å¯ä»¥å¼€å§‹å—ï¼Ÿ")
    return "\n".join(lines)


def render_clarification(plan) -> str:
    """Render clarification question."""
    if not plan.clarification:
        return "è¯·æä¾›æ›´å¤šä¿¡æ¯ã€‚"
    
    clar = plan.clarification
    lines = [clar.get("question", "è¯·æä¾›æ›´å¤šä¿¡æ¯"), ""]
    
    if options := clar.get("options"):
        for i, opt in enumerate(options, 1):
            lines.append(f"{i}) {opt}")
    
    return "\n".join(lines)


def render_research_result(result: ResearchResult) -> str:
    """Render research result."""
    lines = [f"# ç ”ç©¶ç»“æœï¼š{result.goal}", ""]
    
    if result.synthesis:
        lines.append("## ç»¼åˆæŠ¥å‘Š")
        lines.append(result.synthesis)
        lines.append("")
    
    if result.findings:
        lines.append("## è¯¦ç»†å‘ç°")
        for focus, finding in result.findings.items():
            lines.append(f"### {focus}")
            for f in finding.findings:
                lines.append(f"- {f}")
            if finding.sources:
                lines.append("\n**æ¥æºï¼š**")
                for src in finding.sources[:3]:  # Show top 3 sources
                    lines.append(f"- [{src.title}]({src.url})")
            lines.append("")
    
    if result.citations:
        lines.append("## å¼•ç”¨")
        for cit in result.citations:
            lines.append(f"- {cit.text}")
            for src in cit.sources:
                lines.append(f"  - [{src.title}]({src.url})")
    
    return "\n".join(lines)


def is_confirmation(text: str) -> bool:
    """ç”¨äºç¡®è®¤ CONFIRM_PLAN çš„å¿«æ·ç¡®è®¤ã€‚"""
    confirms = [
        "å¯ä»¥", "å¥½", "ok", "OK", "å¼€å§‹", "è¡Œ", "æ²¡é—®é¢˜", "å°±è¿™æ ·", "ç¡®è®¤",
        "yes", "å¥½çš„", "å¯ä»¥çš„", "go", "ç»§ç»­", "æ˜¯çš„", "å¯¹", "å—¯", "å¯ä»¥å¼€å§‹"
    ]
    t = text.strip().lower()
    # é¿å…æŠŠé•¿å¥è¯¯åˆ¤ä¸ºç¡®è®¤
    return any(c.lower() in t for c in confirms) and len(t) < 20


def is_clarification_response(text: str, options: list) -> Optional[int]:
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦é€‰æ‹©äº†æ¾„æ¸…é€‰é¡¹ã€‚
    
    Args:
        text: ç”¨æˆ·è¾“å…¥
        options: æ¾„æ¸…é€‰é¡¹åˆ—è¡¨
    
    Returns:
        é€‰é¡¹ç´¢å¼•ï¼ˆ1-basedï¼‰ï¼Œå¦‚æœä¸æ˜¯æœ‰æ•ˆé€‰æ‹©åˆ™è¿”å› None
    """
    text = text.strip()
    
    # æ£€æŸ¥æ•°å­—é€‰æ‹©ï¼ˆ1, 2, 3...ï¼‰
    try:
        choice = int(text)
        if 1 <= choice <= len(options):
            return choice
    except ValueError:
        pass
    
    # æ£€æŸ¥æ–‡æœ¬åŒ¹é…
    text_lower = text.lower()
    for i, opt in enumerate(options, 1):
        if opt.lower() in text_lower or text_lower in opt.lower():
            return i
    
    return None


async def main():
    """
    ä¸»å¾ªç¯ï¼šä½¿ç”¨ Orchestrator åè°ƒæ•´ä¸ªç ”ç©¶æµç¨‹
    - Clarifier è¯„ä¼°ä¿¡æ¯å……åˆ†æ€§
    - Planner åˆ†è§£ä»»åŠ¡
    - Executor å¹¶è¡Œæ‰§è¡Œ
    - Synthesizer ç»¼åˆç»“æœ
    """
    # Build models for different modules
    base_model = build_model()
    clarifier_model = build_model()  # Can use different model
    planner_model = build_model()
    executor_model = build_model()
    synthesizer_model = build_model()
    
    # Create orchestrator
    orchestrator = Orchestrator(
        clarifier_model=clarifier_model,
        planner_model=planner_model,
        executor_model=executor_model,
        synthesizer_model=synthesizer_model,
        max_parallel=MAX_PARALLEL_SUBAGENTS
    )
    
    state = SessionState()
    pending_plan = None

    print("ğŸ§ª Deep Research Agent\n")

    while True:
        user = input("User> ").strip()
        if not user:
            continue
        
        # Handle confirmation
        if pending_plan and is_confirmation(user):
            add_user(state, "[ç”¨æˆ·ç¡®è®¤] å·²ç¡®è®¤æŒ‰è®¡åˆ’æ‰§è¡Œ")
            pending_plan = None
            
            # Re-run orchestrator with confirmation
            plan, research_result = await orchestrator.run(
                user_input=user,
                messages=state.messages,
                task_draft=state.task_draft
            )
            
            if research_result:
                print("\n" + render_research_result(research_result))
                add_assistant(state, render_research_result(research_result))
            continue
        
        # Normal input
        add_user(state, user)
        pending_plan = None
        
        # Run orchestrator
        plan, research_result = await orchestrator.run(
            user_input=user,
            messages=state.messages,
            task_draft=state.task_draft
        )
        
        print(f"[DEBUG] next_action: {plan.next_action}, confidence: {plan.confidence}")
        
        # Handle different actions
        if plan.next_action == "START_RESEARCH":
            print("ğŸ” å¼€å§‹ç ”ç©¶...")
            if research_result:
                print("\n" + render_research_result(research_result))
                add_assistant(state, render_research_result(research_result))
            else:
                print("âš ï¸ ç ”ç©¶å·²å®Œæˆï¼Œä½†æœªè¿”å›ç»“æœã€‚")
                add_assistant(state, "ç ”ç©¶å·²å®Œæˆï¼Œä½†æœªè¿”å›ç»“æœã€‚")
            update_task_draft(state, plan.task.model_dump())
            continue

        elif plan.next_action == "NEED_CLARIFICATION":
            update_task_draft(state, plan.task.model_dump())
            response = render_clarification(plan)
            print(response)
            add_assistant(state, response)
            pending_plan = plan
            
            # Wait for user clarification response
            clar_response = input("\nè¯·é€‰æ‹©ï¼ˆè¾“å…¥æ•°å­—æˆ–é€‰é¡¹ï¼‰> ").strip()
            if clar_response:
                # Check if user selected an option
                options = plan.clarification.get("options", []) if plan.clarification else []
                choice = is_clarification_response(clar_response, options)
                
                # #region debug log
                import json, time
                with open("/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log", "a") as f:
                    f.write(json.dumps({"sessionId": "debug-session", "runId": "run1", "hypothesisId": "H1", "location": "main.py:clarification_input", "message": "User clarification input", "data": {"clar_response": clar_response, "options_count": len(options), "options": options[:3], "choice": choice}, "timestamp": time.time() * 1000}) + "\n")
                # #endregion
                
                if choice:
                    selected_option = options[choice - 1] if choice <= len(options) else clar_response
                    # Add clarification response to conversation
                    add_user(state, f"[æ¾„æ¸…å›å¤] {selected_option}")
                    # Update task_draft with clarification
                    if plan.clarification:
                        missing_info = plan.clarification.get("missing_info", "")
                        if missing_info == "research_topic":
                            state.task_draft["goal"] = selected_option
                        elif missing_info == "research_focus":
                            if "research_focus" not in state.task_draft:
                                state.task_draft["research_focus"] = []
                            state.task_draft["research_focus"].append(selected_option)
                    
                    # Re-run orchestrator with clarification
                    plan, research_result = await orchestrator.run(
                        user_input=selected_option,
                        messages=state.messages,
                        task_draft=state.task_draft
                    )
                    
                    # #region debug log
                    with open("/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps({"sessionId": "debug-session", "runId": "run1", "hypothesisId": "H2_H3", "location": "main.py:after_rerun", "message": "After orchestrator rerun", "data": {"next_action": plan.next_action, "has_research_result": research_result is not None, "confidence": plan.confidence}, "timestamp": time.time() * 1000}) + "\n")
                    # #endregion
                    
                    # Handle the new plan
                    if plan.next_action == "START_RESEARCH" and research_result:
                        print("\n" + render_research_result(research_result))
                        add_assistant(state, render_research_result(research_result))
                    elif plan.next_action == "NEED_CLARIFICATION":
                        # Still need more clarification
                        response = render_clarification(plan)
                        print(response)
                        add_assistant(state, response)
                        pending_plan = plan
                    else:
                        # #region debug log
                        with open("/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log", "a") as f:
                            f.write(json.dumps({"sessionId": "debug-session", "runId": "run1", "hypothesisId": "H2", "location": "main.py:unhandled_action", "message": "Unhandled next_action after clarification", "data": {"next_action": plan.next_action, "has_research_result": research_result is not None}, "timestamp": time.time() * 1000}) + "\n")
                        # #endregion
                        print(f"[DEBUG] æœªå¤„ç†çš„çŠ¶æ€: next_action={plan.next_action}, has_result={research_result is not None}")
                else:
                    # #region debug log
                    with open("/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps({"sessionId": "debug-session", "runId": "run1", "hypothesisId": "H1", "location": "main.py:no_choice", "message": "No valid choice detected", "data": {"clar_response": clar_response, "options": options}, "timestamp": time.time() * 1000}) + "\n")
                    # #endregion
                    print(f"[DEBUG] æœªèƒ½è¯†åˆ«é€‰é¡¹ï¼š{clar_response}")
            continue

        elif plan.next_action == "CONFIRM_PLAN":
            update_task_draft(state, plan.task.model_dump())
            response = render_plan(plan)
            print(response)
            add_assistant(state, response)
            pending_plan = plan
            continue
            
        elif plan.next_action == "VERIFY_TOPIC":
            topic = plan.unknown_topic or "unknown"
            print(f"ğŸ” æ­£åœ¨éªŒè¯ã€Œ{topic}ã€...")
            add_assistant(state, f"æ­£åœ¨éªŒè¯ã€Œ{topic}ã€...")
            # Orchestrator already handles VERIFY_TOPIC, so we just continue
            continue
            
        elif plan.next_action == "CANNOT_DO":
            reason = plan.block.reason or "è¿™ä¸ªæˆ‘æš‚æ—¶åšä¸äº†ã€‚"
            print(reason)
            if plan.block.alternatives:
                print("æˆ‘å¯ä»¥å¸®ä½ ï¼š")
                for i, a in enumerate(plan.block.alternatives, 1):
                    print(f"  {i}) {a}")
            add_assistant(state, reason)
            continue

        # Fallback
        print(f"[WARN] æœªå¤„ç†çš„ next_action: {plan.next_action}")
        add_assistant(state, f"[WARN] æœªå¤„ç†çš„ next_action: {plan.next_action}")


if __name__ == "__main__":
    asyncio.run(main())
