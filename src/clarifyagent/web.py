"""Web API for ClarifyAgent - Deep Research Platform."""
import asyncio
import json
import uuid
from typing import Optional, AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse
from pydantic import BaseModel
import logging

from .agent import build_model
from .config import MAX_PARALLEL_SUBAGENTS
from .orchestrator import Orchestrator
from .dialog import SessionState, add_user, add_assistant, update_task_draft, save_research_result, is_simple_followup, is_new_research_task, start_new_research_session
from .schema import ResearchResult

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="ClarifyAgent",
    description="Deep Research Platform with Intelligent Clarification",
    version="1.0.0"
)

# Session storage (in-memory for demo)
sessions: dict[str, dict] = {}


class ChatRequest(BaseModel):
    session_id: Optional[str] = None
    message: str


class ChatResponse(BaseModel):
    session_id: str
    response_type: str  # "clarification" | "research_result" | "confirm_plan" | "quick_answer" | "error"
    message: str
    options: Optional[list[str]] = None
    research_result: Optional[dict] = None
    next_action: Optional[str] = None


def get_or_create_session(session_id: Optional[str]) -> tuple[str, dict]:
    """Get existing session or create new one."""
    if session_id and session_id in sessions:
        return session_id, sessions[session_id]
    
    new_id = str(uuid.uuid4())[:8]
    sessions[new_id] = {
        "state": SessionState(),
        "pending_plan": None,
        "orchestrator": None
    }
    return new_id, sessions[new_id]


def create_orchestrator() -> Orchestrator:
    """Create a new orchestrator instance with different models for different purposes."""
    return Orchestrator(
        clarifier_model=build_model("clarifier"),
        planner_model=build_model("planner"),
        executor_model=build_model("executor"),
        synthesizer_model=build_model("synthesizer"),
        max_parallel=MAX_PARALLEL_SUBAGENTS
    )


def render_clarification(plan) -> tuple[str, list[str]]:
    """Render clarification question and options."""
    if not plan.clarification:
        return "è¯·æä¾›æ›´å¤šä¿¡æ¯ã€‚", []
    
    clar = plan.clarification
    question = clar.get("question", "è¯·æä¾›æ›´å¤šä¿¡æ¯")
    options = clar.get("options", [])
    
    return question, options


def render_plan(plan, subtasks=None) -> str:
    """
    Render plan for confirmation.

    Args:
        plan: Plan object from Clarifier
        subtasks: Optional list of Subtask objects from Planner
    """
    task = plan.task
    lines = [f"æˆ‘ç†è§£ä½ æƒ³åšï¼š**{task.goal}**", ""]
    
    # if getattr(task, "research_focus", None) and task.research_focus:
    #     lines.append("è®¡åˆ’é‡ç‚¹è¦†ç›–ï¼š")
    #     for f in task.research_focus:
    #         lines.append(f"â€¢ {f}")
    #     lines.append("")

    # if getattr(plan, "assumptions", None) and plan.assumptions:
    #     lines.append("*æˆ‘çš„å‡è®¾ï¼š" + "ï¼›".join(plan.assumptions) + "*")
    #     lines.append("")

    # lines.append("---")
    # lines.append("")
    lines.append(plan.confirm_prompt or "âœ… ç¡®è®¤å¼€å§‹ç ”ç©¶ï¼Ÿ")
    lines.append("")
    # lines.append("ğŸ’¡ æç¤ºï¼šå¦‚éœ€ä¿®æ”¹è®¡åˆ’ï¼Œè¯·ç›´æ¥æè¿°æ‚¨çš„éœ€æ±‚")

    return "\n".join(lines)

# ============== ä¿®æ”¹ web.py ä¸­çš„ render_research_result å‡½æ•° ==============
# å°†ä¸‹é¢çš„å‡½æ•°æ›¿æ¢ web.py ä¸­åŸæ¥çš„ render_research_result å‡½æ•° (çº¦ç¬¬ 101-139 è¡Œ)

from urllib.parse import urlparse

def is_valid_url(url: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ URL æ ¼å¼"""
    if not url or not isinstance(url, str):
        return False
    
    url = url.strip()
    if not url:
        return False
    
    # åŸºæœ¬æ ¼å¼æ£€æŸ¥
    if not url.startswith(('http://', 'https://')):
        return False
    
    try:
        parsed = urlparse(url)
        # å¿…é¡»æœ‰ scheme å’Œ netloc
        if not parsed.scheme or not parsed.netloc:
            return False
        # netloc å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªç‚¹ï¼ˆåŸŸåï¼‰
        if '.' not in parsed.netloc:
            return False
        return True
    except Exception:
        return False


def render_research_result(result: ResearchResult) -> dict:
    """
    Render research result as structured data.
    å¢å¼ºç‰ˆï¼šæ›´ä¸¥æ ¼çš„ URL éªŒè¯
    """
    # Findings sources come from subtask_results (search results), so they should be valid
    # Citations sources are already validated in synthesizer
    # We add extra validation here as a safety net
    
    filtered_findings = {}
    if result.findings:
        for focus, finding in result.findings.items():
            # ä¸¥æ ¼è¿‡æ»¤ï¼šåªä¿ç•™æœ‰æ•ˆ URL æ ¼å¼çš„ sources
            valid_sources = []
            for s in finding.sources[:3]:
                if is_valid_url(s.url):
                    valid_sources.append(s)
                else:
                    print(f"[WARN] render_research_result: Filtering invalid URL in findings: {s.url[:100] if s.url else 'None'}")
            
            filtered_findings[focus] = {
                "findings": finding.findings[:5],
                "sources": [
                    {
                        "title": s.title or "Unknown",
                        "url": s.url,
                        "snippet": (s.snippet[:200] if s.snippet else "") if s.snippet else ""
                    }
                    for s in valid_sources
                ],
                "confidence": finding.confidence
            }
    
    # Citations are already validated in synthesizer to only include valid URLs
    # But we double-check to ensure URLs are valid format
    filtered_citations = []
    for cit in result.citations[:10]:
        # ä¸¥æ ¼è¿‡æ»¤ï¼šåªä¿ç•™æœ‰æ•ˆ URL æ ¼å¼çš„ sources
        valid_cit_sources = []
        for s in cit.sources:
            if is_valid_url(s.url):
                valid_cit_sources.append(s)
            else:
                print(f"[WARN] render_research_result: Filtering invalid URL in citations: {s.url[:100] if s.url else 'None'}")
        
        if valid_cit_sources:  # Only add citation if it has at least one valid source
            filtered_citations.append({
                "text": cit.text,
                "sources": [{"title": s.title or "Unknown", "url": s.url} for s in valid_cit_sources]
            })
    
    return {
        "goal": result.goal,
        "synthesis": result.synthesis,
        "research_focus": result.research_focus,
        "findings": filtered_findings,
        "citations": filtered_citations
    }



def is_confirmation(text: str) -> bool:
    """Check if text is a confirmation."""
    confirms = [
        "å¯ä»¥", "å¥½", "ok", "OK", "å¼€å§‹", "è¡Œ", "æ²¡é—®é¢˜", "å°±è¿™æ ·", "ç¡®è®¤",
        "yes", "å¥½çš„", "å¯ä»¥çš„", "go", "ç»§ç»­", "æ˜¯çš„", "å¯¹", "å—¯", "å¯ä»¥å¼€å§‹"
    ]
    t = text.strip().lower()
    return any(c.lower() in t for c in confirms) and len(t) < 20


def is_option_selection(text: str, options: list) -> Optional[int]:
    """Check if text is an option selection."""
    text = text.strip()
    try:
        choice = int(text)
        if 1 <= choice <= len(options):
            return choice
    except ValueError:
        pass
    
    text_lower = text.lower()
    for i, opt in enumerate(options, 1):
        if opt.lower() in text_lower or text_lower in opt.lower():
            return i
    return None


@app.get("/", response_class=HTMLResponse)
async def index():
    """Serve the main page."""
    return FileResponse("src/clarifyagent/static/index.html")


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Handle chat messages."""
    session_id, session = get_or_create_session(request.session_id)
    state = session["state"]
    pending_plan = session["pending_plan"]
    
    # Create orchestrator if needed
    if session["orchestrator"] is None:
        session["orchestrator"] = create_orchestrator()
    orchestrator = session["orchestrator"]
    
    user_message = request.message.strip()
    if not user_message:
        raise HTTPException(status_code=400, detail="Message cannot be empty")
    
    try:
        # Handle confirmation for pending plan
        if pending_plan and is_confirmation(user_message):
            add_user(state, "[ç”¨æˆ·ç¡®è®¤] å·²ç¡®è®¤æŒ‰è®¡åˆ’æ‰§è¡Œ")
            session["pending_plan"] = None
            
            plan, research_result = await orchestrator.run(
                user_input=user_message,
                messages=state.messages,
                task_draft=state.task_draft
            )
            
            if research_result:
                add_assistant(state, f"ç ”ç©¶å®Œæˆï¼š{research_result.goal}")
                return ChatResponse(
                    session_id=session_id,
                    response_type="research_result",
                    message="ç ”ç©¶å®Œæˆï¼",
                    research_result=render_research_result(research_result),
                    confidence=plan.confidence,
                    next_action=plan.next_action
                )
            else:
                return ChatResponse(
                    session_id=session_id,
                    response_type="error",
                    message="ç ”ç©¶å·²å®Œæˆï¼Œä½†æœªè¿”å›ç»“æœã€‚"
                )
        
        # Handle option selection for clarification
        if pending_plan and pending_plan.clarification:
            options = pending_plan.clarification.get("options", [])
            choice = is_option_selection(user_message, options)
            if choice:
                selected_option = options[choice - 1]
                add_user(state, f"[æ¾„æ¸…å›å¤] {selected_option}")
                
                # Update task draft
                missing_info = pending_plan.clarification.get("missing_info", "")
                if missing_info == "research_topic":
                    state.task_draft["goal"] = selected_option
                elif missing_info == "research_focus":
                    if "research_focus" not in state.task_draft:
                        state.task_draft["research_focus"] = []
                    state.task_draft["research_focus"].append(selected_option)
                
                session["pending_plan"] = None
                user_message = selected_option
        
        # Normal input processing
        add_user(state, user_message)
        
        plan, research_result = await orchestrator.run(
            user_input=user_message,
            messages=state.messages,
            task_draft=state.task_draft
        )
        
        logger.info(f"[API] next_action: {plan.next_action}, confidence: {plan.confidence}")
        
        # Handle different actions
        if plan.next_action == "START_RESEARCH":
            if research_result:
                add_assistant(state, f"ç ”ç©¶å®Œæˆï¼š{research_result.goal}")
                update_task_draft(state, plan.task.model_dump())
                return ChatResponse(
                    session_id=session_id,
                    response_type="research_result",
                    message="ğŸ” ç ”ç©¶å®Œæˆï¼",
                    research_result=render_research_result(research_result),
                    confidence=plan.confidence,
                    next_action=plan.next_action
                )
            else:
                return ChatResponse(
                    session_id=session_id,
                    response_type="error",
                    message="ç ”ç©¶å·²å¯åŠ¨ä½†æœªè¿”å›ç»“æœã€‚",
                    confidence=plan.confidence,
                    next_action=plan.next_action
                )
        
        elif plan.next_action == "NEED_CLARIFICATION":
            update_task_draft(state, plan.task.model_dump())
            question, options = render_clarification(plan)
            add_assistant(state, question)
            session["pending_plan"] = plan
            
            return ChatResponse(
                session_id=session_id,
                response_type="clarification",
                message=question,
                options=options,
                confidence=plan.confidence,
                next_action=plan.next_action
            )
        
        elif plan.next_action == "CONFIRM_PLAN":
            update_task_draft(state, plan.task.model_dump())
            message = render_plan(plan)
            add_assistant(state, message)
            session["pending_plan"] = plan
            
            return ChatResponse(
                session_id=session_id,
                response_type="confirm_plan",
                message=message,
                confidence=plan.confidence,
                next_action=plan.next_action
            )
        
        elif plan.next_action == "VERIFY_TOPIC":
            topic = plan.unknown_topic or "unknown"
            message = f"ğŸ” æ­£åœ¨éªŒè¯ã€Œ{topic}ã€..."
            add_assistant(state, message)
            
            return ChatResponse(
                session_id=session_id,
                response_type="verifying",
                message=message,
                confidence=plan.confidence,
                next_action=plan.next_action
            )
        
        elif plan.next_action == "CANNOT_DO":
            reason = plan.block.reason if plan.block else "è¿™ä¸ªæˆ‘æš‚æ—¶åšä¸äº†ã€‚"
            alternatives = plan.block.alternatives if plan.block else []
            message = reason
            if alternatives:
                message += "\n\næˆ‘å¯ä»¥å¸®ä½ ï¼š\n" + "\n".join([f"â€¢ {a}" for a in alternatives])
            add_assistant(state, message)
            
            return ChatResponse(
                session_id=session_id,
                response_type="cannot_do",
                message=message,
                options=alternatives,
                confidence=plan.confidence,
                next_action=plan.next_action
            )
        
        # Fallback
        return ChatResponse(
            session_id=session_id,
            response_type="error",
            message=f"æœªå¤„ç†çš„çŠ¶æ€: {plan.next_action}",
            confidence=plan.confidence,
            next_action=plan.next_action
        )
    
    except Exception as e:
        logger.exception(f"Error processing chat: {e}")
        return ChatResponse(
            session_id=session_id,
            response_type="error",
            message=f"å¤„ç†å‡ºé”™: {str(e)}"
        )


@app.get("/api/session/{session_id}")
async def get_session(session_id: str):
    """Get session info."""
    if session_id not in sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = sessions[session_id]
    return {
        "session_id": session_id,
        "message_count": len(session["state"].messages),
        "has_pending_plan": session["pending_plan"] is not None
    }


@app.delete("/api/session/{session_id}")
async def clear_session(session_id: str):
    """Clear a session."""
    if session_id in sessions:
        del sessions[session_id]
    return {"status": "ok"}


async def stream_generator(session_id: str, message: str) -> AsyncGenerator[str, None]:
    """Generate SSE events for streaming responses."""
    # #region agent log
    import json as json_lib
    log_path = "/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log"
    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json_lib.dumps({
                "sessionId": "debug-session",
                "runId": "run1",
                "hypothesisId": "SESSION_ENTRY",
                "location": "web.py:stream_generator_entry",
                "message": "stream_generator entry - checking session_id",
                "data": {
                    "incoming_session_id": session_id,
                    "message_preview": message[:100] if message else "",
                    "sessions_keys": list(sessions.keys()),
                },
                "timestamp": int(__import__("time").time() * 1000)
            }, ensure_ascii=False) + "\n")
    except: pass
    # #endregion
    
    session_id, session = get_or_create_session(session_id if session_id != "new" else None)
    state = session["state"]
    pending_plan = session["pending_plan"]
    
    # #region agent log
    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json_lib.dumps({
                "sessionId": "debug-session",
                "runId": "run1",
                "hypothesisId": "SESSION_AFTER",
                "location": "web.py:stream_generator_after_session",
                "message": "session retrieved/created",
                "data": {
                    "final_session_id": session_id,
                    "messages_count": len(state.messages),
                    "task_draft_keys": list(state.task_draft.keys()),
                    "has_pending_plan": pending_plan is not None,
                },
                "timestamp": int(__import__("time").time() * 1000)
            }, ensure_ascii=False) + "\n")
    except: pass
    # #endregion
    
    # Send session ID first
    yield f"data: {json.dumps({'type': 'session', 'session_id': session_id})}\n\n"

    # Import dependencies at the beginning so all branches can access them
    from .clarifier import assess_input
    from .planner import decompose_task
    from .executor import Executor
    from .synthesizer import synthesize_results
    from .schema import Subtask
    from .agent import build_model

    try:
        user_message = message.strip()
        if not user_message:
            yield f"data: {json.dumps({'type': 'error', 'message': 'Message cannot be empty'})}\n\n"
            return
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„è°ƒç ”ä»»åŠ¡ï¼ˆåœ¨chatæ¨¡å¼ä¸‹ï¼‰
        if state.conversation_mode == "chat" and is_new_research_task(user_message, state):
            print(f"[DEBUG] Detected new research task in chat mode, starting new research session")
            start_new_research_session(state)
            # ç»™ç”¨æˆ·ä¸€ä¸ªæç¤ºï¼Œè¡¨æ˜å¼€å§‹æ–°çš„ç ”ç©¶
            yield f"data: {json.dumps({'type': 'progress', 'stage': 'new_research', 'message': 'å¼€å§‹æ–°çš„è°ƒç ”ä»»åŠ¡', 'detail': f'æ£€æµ‹åˆ°æ–°è°ƒç ”éœ€æ±‚ï¼Œå·²ä¿å­˜ä¹‹å‰çš„ç ”ç©¶ç»“æœ'})}\n\n"
            await asyncio.sleep(0.1)
            # ç»§ç»­æ‰§è¡Œå®Œæ•´ç ”ç©¶æµç¨‹
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç®€å•åç»­å¯¹è¯
        elif is_simple_followup(user_message, state):
            print(f"[DEBUG] Detected simple followup, using chat mode")
            add_user(state, user_message)
            
            try:
                chat_response = await handle_simple_chat(state, user_message)
                add_assistant(state, chat_response)
                save_research_result(state, state.last_research_result)  # ä¿æŒèŠå¤©æ¨¡å¼
                yield f"data: {json.dumps({'type': 'result', 'response_type': 'simple_chat', 'message': chat_response})}\n\n"
                return
            except Exception as e:
                print(f"[ERROR] Simple chat failed: {e}")
                # é™çº§åˆ°å®Œæ•´ç ”ç©¶æ¨¡å¼
                pass
        
        # Handle plan modification request
        if pending_plan and (user_message.startswith("ä¿®æ”¹è®¡åˆ’:") or user_message.startswith("ä¿®æ”¹è®¡åˆ’ï¼š")):
            modification = user_message.split(":", 1)[1].strip() if ":" in user_message else user_message.split("ï¼š", 1)[1].strip()
            add_user(state, f"[ä¿®æ”¹è®¡åˆ’] {modification}")
            session["pending_plan"] = None
            
            # Add modification to task draft context
            if "modification_notes" not in state.task_draft:
                state.task_draft["modification_notes"] = []
            state.task_draft["modification_notes"].append(modification)
            
            # Continue to re-assess with modification
            user_message = modification
        
        # Handle confirmation for pending plan
        elif pending_plan and is_confirmation(user_message):
            add_user(state, user_message)  # ä¿ç•™ç”¨æˆ·çš„å®é™…è¾“å…¥ï¼Œå¦‚"ç¡®è®¤å¼€å§‹ç ”ç©¶"

            # ä½¿ç”¨å·²ä¿å­˜çš„ subtasksï¼ˆå¦‚æœæœ‰ï¼‰
            planned_subtasks = session.get("planned_subtasks")

            session["pending_plan"] = None
            session["planned_subtasks"] = None  # æ¸…é™¤å·²ä½¿ç”¨çš„è®¡åˆ’

            yield f"data: {json.dumps({'type': 'progress', 'stage': 'executing', 'message': 'å¼€å§‹æ‰§è¡Œç ”ç©¶...', 'detail': 'æŒ‰è®¡åˆ’è¿›è¡Œæ·±å…¥è°ƒç ”'})}\n\n"
            await asyncio.sleep(0.1)

            # æ„å»º modelï¼ˆç¡®è®¤åˆ†æ”¯ä¸­éœ€è¦ï¼‰
            model = build_model()

            # å¦‚æœæœ‰é¢„å…ˆè§„åˆ’çš„ subtasksï¼Œç›´æ¥ä½¿ç”¨å®ƒä»¬æ‰§è¡Œ
            if planned_subtasks and len(planned_subtasks) > 0:
                try:
                    # Step 3: ç›´æ¥æ‰§è¡Œå·²è§„åˆ’çš„ subtasks
                    focus_preview = ', '.join([s.focus[:20] for s in planned_subtasks[:3]]) + ('...' if len(planned_subtasks) > 3 else '')
                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'searching', 'message': f'æ£€ç´¢ä¿¡æ¯ ({len(planned_subtasks)} ä¸ªæ–¹å‘)', 'detail': f'æ­£åœ¨å¹¶è¡Œæ£€ç´¢ï¼š{focus_preview}'})}\n\n"
                    await asyncio.sleep(0.1)

                    executor = Executor(model, max_parallel=len(planned_subtasks))

                    # å¹¶è¡Œæ‰§è¡Œ
                    import time
                    from .tools.concurrency_manager import run_concurrent_tasks

                    parallel_start = time.time()
                    tasks = [executor.execute_single(subtask) for subtask in planned_subtasks]
                    results = await run_concurrent_tasks(tasks)
                    parallel_end = time.time()

                    print(f"[DEBUG] Executed planned subtasks: {parallel_end - parallel_start:.2f}s")

                    subtask_results = [r for r in results if r is not None and not isinstance(r, Exception)]

                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'searching', 'message': f'æ£€ç´¢å®Œæˆ ({len(subtask_results)}/{len(planned_subtasks)})', 'detail': f'å·²è·å– {len(subtask_results)} ä¸ªç ”ç©¶æ–¹å‘çš„ä¿¡æ¯'})}\n\n"
                    await asyncio.sleep(0.1)

                    if not subtask_results:
                        yield f"data: {json.dumps({'type': 'error', 'message': 'æ£€ç´¢å¤±è´¥ï¼Œæœªè·å–åˆ°ç»“æœ'})}\n\n"
                        return

                    # Step 4: Synthesizer
                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'synthesizing', 'message': 'æ•´åˆåˆ†æç»“æœ', 'detail': f'æ­£åœ¨ç»¼åˆåˆ†æ {len(subtask_results)} ä¸ªç ”ç©¶æ–¹å‘çš„ä¿¡æ¯'})}\n\n"
                    await asyncio.sleep(0.1)

                    research_result = await synthesize_results(
                        model,
                        pending_plan.task.goal,
                        pending_plan.task.research_focus,
                        subtask_results
                    )

                    yield f"data: {json.dumps({'type': 'progress', 'stage': 'complete', 'message': 'ç ”ç©¶å®Œæˆ', 'detail': 'ç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ'})}\n\n"

                    add_assistant(state, f"ç ”ç©¶å®Œæˆï¼š{research_result.goal}")
                    update_task_draft(state, pending_plan.task.model_dump())
                    save_research_result(state, render_research_result(research_result))

                    yield f"data: {json.dumps({'type': 'result', 'response_type': 'research_result', 'message': 'ç ”ç©¶å®Œæˆï¼', 'research_result': render_research_result(research_result)})}\n\n"
                    return

                except Exception as e:
                    logger.exception(f"Execution error: {e}")
                    yield f"data: {json.dumps({'type': 'error', 'message': f'æ‰§è¡Œå‡ºé”™: {str(e)}'})}\n\n"
                    return

            # å¦åˆ™ï¼Œä½¿ç”¨ Orchestrator å®Œæ•´æµç¨‹
            else:
                orchestrator = create_orchestrator()
                plan, research_result = await orchestrator.run(
                    user_input=user_message,
                    messages=state.messages,
                    task_draft=state.task_draft
                )

                if research_result:
                    add_assistant(state, f"ç ”ç©¶å®Œæˆï¼š{research_result.goal}")
                    yield f"data: {json.dumps({'type': 'result', 'response_type': 'research_result', 'message': 'ç ”ç©¶å®Œæˆï¼', 'research_result': render_research_result(research_result)})}\n\n"
                else:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'ç ”ç©¶å·²å®Œæˆï¼Œä½†æœªè¿”å›ç»“æœã€‚'})}\n\n"
            return
        
        # Handle clarification response (options or open-ended)
        # æ³¨æ„ï¼šåªæœ‰åœ¨ä¸æ˜¯ç¡®è®¤çš„æƒ…å†µä¸‹æ‰å¤„ç†æ¾„æ¸…å›å¤
        if pending_plan and pending_plan.clarification and not is_confirmation(user_message):
            options = pending_plan.clarification.get("options", [])
            missing_info = pending_plan.clarification.get("missing_info", "")
            is_open_ended = pending_plan.clarification.get("open_ended", False) or not options
            
            # #region agent log
            import json as json_lib
            import os
            log_path = "/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log"
            try:
                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(json_lib.dumps({
                        "sessionId": "debug-session",
                        "runId": "run1",
                        "hypothesisId": "F",
                        "location": "web.py:409",
                        "message": "clarification response detected",
                        "data": {
                            "user_message": user_message,
                            "missing_info": missing_info,
                            "is_open_ended": is_open_ended,
                            "task_draft_before": dict(state.task_draft),
                        },
                        "timestamp": int(__import__("time").time() * 1000)
                    }, ensure_ascii=False) + "\n")
            except: pass
            # #endregion
            
            if is_open_ended:
                # å¼€æ”¾å¼é—®é¢˜ï¼šç”¨æˆ·ç›´æ¥è¾“å…¥ä¿¡æ¯
                # å°†ç”¨æˆ·å›ç­”ä¸åŸå§‹é—®é¢˜å…³è”ï¼Œæ›´æ–°åˆ° task_draft
                add_user(state, user_message)  # ä¿ç•™ç”¨æˆ·çš„åŸå§‹è¾“å…¥ï¼Œä¸æ·»åŠ æ ‡ç­¾
                
                if missing_info in ("pipeline_details", "project_details"):
                    # è§£æç”¨æˆ·æä¾›çš„é¡¹ç›®/äº§å“ä¿¡æ¯ï¼Œè¡¥å……åˆ° task_draft
                    state.task_draft["project_info"] = user_message
                    # å°è¯•ä»ç”¨æˆ·å›ç­”ä¸­æå–å…³é”®ä¿¡æ¯
                    original_goal = state.task_draft.get("goal", "")
                    state.task_draft["goal"] = f"{original_goal}ï¼ˆ{user_message}ï¼‰"
                elif missing_info == "research_topic":
                    state.task_draft["goal"] = user_message
                else:
                    # é€šç”¨å¤„ç†ï¼šå°†ç”¨æˆ·å›ç­”æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                    if "clarification_responses" not in state.task_draft:
                        state.task_draft["clarification_responses"] = []
                    state.task_draft["clarification_responses"].append({
                        "question": pending_plan.clarification.get("question", ""),
                        "answer": user_message
                    })
                
                # #region agent log
                try:
                    with open(log_path, "a", encoding="utf-8") as f:
                        f.write(json_lib.dumps({
                            "sessionId": "debug-session",
                            "runId": "run1",
                            "hypothesisId": "G",
                            "location": "web.py:440",
                            "message": "task_draft updated after open-ended answer",
                            "data": {
                                "task_draft_after": dict(state.task_draft),
                                "project_info": state.task_draft.get("project_info", ""),
                                "goal": state.task_draft.get("goal", ""),
                            },
                            "timestamp": int(__import__("time").time() * 1000)
                        }, ensure_ascii=False) + "\n")
                except: pass
                # #endregion
                
                session["pending_plan"] = None
                # ä¸æ”¹å˜ user_messageï¼Œè®©å®ƒåŒ…å«å®Œæ•´çš„ç”¨æˆ·è¾“å…¥
                # æ³¨æ„ï¼šå·²ç»åœ¨ä¸Šé¢ add_user äº†ï¼Œä¸éœ€è¦å†æ¬¡æ·»åŠ 
                skip_add_user = True
                
            else:
                # é€‰é¡¹å¼é—®é¢˜
                choice = is_option_selection(user_message, options)
                if choice:
                    selected_option = options[choice - 1]
                    add_user(state, selected_option)  # ä¿ç•™ç”¨æˆ·çš„åŸå§‹é€‰æ‹©ï¼Œä¸æ·»åŠ æ ‡ç­¾
                    
                    if missing_info == "research_topic":
                        state.task_draft["goal"] = selected_option
                    elif missing_info == "research_focus":
                        if "research_focus" not in state.task_draft:
                            state.task_draft["research_focus"] = []
                        state.task_draft["research_focus"].append(selected_option)
                    
                    session["pending_plan"] = None
                    user_message = selected_option
                    # æ³¨æ„ï¼šå·²ç»åœ¨ä¸Šé¢ add_user äº†ï¼Œä¸éœ€è¦å†æ¬¡æ·»åŠ 
                    skip_add_user = True
                else:
                    skip_add_user = False
        else:
            skip_add_user = False
        
        # Normal input processing (only if not already added above)
        if not skip_add_user:
            add_user(state, user_message)
        
        # Step 1: Clarifier - åˆ†æç ”ç©¶éœ€æ±‚
        yield f"data: {json.dumps({'type': 'progress', 'stage': 'clarifying', 'message': 'åˆ†æç ”ç©¶éœ€æ±‚', 'detail': 'æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜èƒŒæ™¯å’Œç›®æ ‡'})}\n\n"
        await asyncio.sleep(0.1)  # Let the event flush

        model = build_model()
        
        # #region agent log
        import json as json_lib
        import os
        log_path = "/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log"
        try:
            with open(log_path, "a", encoding="utf-8") as f:
                f.write(json_lib.dumps({
                    "sessionId": "debug-session",
                    "runId": "run1",
                    "hypothesisId": "H",
                    "location": "web.py:515",
                    "message": "before assess_input call",
                    "data": {
                        "user_message": user_message,
                        "messages_count": len(state.messages),
                        "task_draft": dict(state.task_draft),
                        "task_draft_goal": state.task_draft.get("goal", ""),
                        "task_draft_project_info": state.task_draft.get("project_info", ""),
                    },
                    "timestamp": int(__import__("time").time() * 1000)
                }, ensure_ascii=False) + "\n")
        except: pass
        # #endregion
        
        # Step 1: Clarifier
        plan = await assess_input(model, state.messages, state.task_draft)
        
        logger.info(f"[API Stream] next_action: {plan.next_action}")
        
        # Handle different actions
        if plan.next_action == "NEED_CLARIFICATION":
            update_task_draft(state, plan.task.model_dump())
            question, options = render_clarification(plan)
            add_assistant(state, question)
            session["pending_plan"] = plan
            
            yield f"data: {json.dumps({'type': 'result', 'response_type': 'clarification', 'message': question, 'options': options})}\n\n"
        
        elif plan.next_action == "CONFIRM_PLAN":
            update_task_draft(state, plan.task.model_dump())

            # åœ¨ç¡®è®¤é˜¶æ®µè°ƒç”¨ Planner ç”Ÿæˆè¯¦ç»†è®¡åˆ’
            yield f"data: {json.dumps({'type': 'progress', 'stage': 'planning', 'message': 'è§„åˆ’ç ”ç©¶æ–¹å‘...', 'detail': 'æ­£åœ¨åˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’'})}\n\n"
            await asyncio.sleep(0.1)

            try:
                subtasks = await decompose_task(model, plan.task)

                if not subtasks:
                    # Fallback: ä» research_focus åˆ›å»ºåŸºæœ¬ subtasks
                    from .schema import Subtask
                    subtasks = [
                        Subtask(
                            id=i + 1,
                            focus=focus,
                            queries=[f"{plan.task.goal} {focus}"],
                            parallel=True
                        )
                        for i, focus in enumerate(plan.task.research_focus[:3])
                    ]

                # ä¿å­˜ subtasks åˆ° session
                session["planned_subtasks"] = subtasks

                # æ¸²æŸ“è¯¦ç»†è®¡åˆ’
                msg = render_plan(plan, subtasks=subtasks)
                add_assistant(state, msg)
                session["pending_plan"] = plan

                yield f"data: {json.dumps({'type': 'result', 'response_type': 'confirm_plan', 'message': msg})}\n\n"

            except Exception as e:
                logger.exception(f"Planning error: {e}")
                # é™çº§ï¼šä¸å±•ç¤ºè¯¦ç»†è®¡åˆ’
                msg = render_plan(plan)
                add_assistant(state, msg)
                session["pending_plan"] = plan
                yield f"data: {json.dumps({'type': 'result', 'response_type': 'confirm_plan', 'message': msg})}\n\n"
        
        elif plan.next_action == "CANNOT_DO":
            reason = plan.block.reason if plan.block else "è¿™ä¸ªæˆ‘æš‚æ—¶åšä¸äº†ã€‚"
            alternatives = plan.block.alternatives if plan.block else []
            msg = reason
            if alternatives:
                msg += "\n\næˆ‘å¯ä»¥å¸®ä½ ï¼š\n" + "\n".join([f"â€¢ {a}" for a in alternatives])
            add_assistant(state, msg)
            
            yield f"data: {json.dumps({'type': 'result', 'response_type': 'cannot_do', 'message': msg, 'options': alternatives})}\n\n"
        
        elif plan.next_action == "START_RESEARCH":
            try:
                # Step 2: Planner - åˆ†æéœ€è¦ç ”ç©¶å“ªäº›æ–¹é¢
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'planning', 'message': 'è§„åˆ’ç ”ç©¶æ–¹å‘', 'detail': f'æ­£åœ¨åˆ†è§£ç ”ç©¶ä»»åŠ¡ï¼š{plan.task.goal}'})}\n\n"
                await asyncio.sleep(0.1)
                
                subtasks = await decompose_task(model, plan.task)
                
                logger.info(f"[Planner] Created {len(subtasks)} subtasks")
                
                if not subtasks:
                    # Fallback: create from research_focus
                    subtasks = [
                        Subtask(
                            id=i + 1,
                            focus=focus,
                            queries=[f"{plan.task.goal} {focus}"],
                            parallel=True
                        )
                        for i, focus in enumerate(plan.task.research_focus[:3])
                    ]
                
                if not subtasks:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'æ— æ³•åˆ›å»ºç ”ç©¶è®¡åˆ’'})}\n\n"
                    return
                
                # æ˜¾ç¤ºç ”ç©¶æ–¹å‘
                focus_list = [s.focus for s in subtasks]
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'planning', 'message': f'å·²è§„åˆ’ {len(subtasks)} ä¸ªç ”ç©¶æ–¹å‘', 'detail': ', '.join(focus_list[:3]) + ('...' if len(focus_list) > 3 else '')})}\n\n"
                await asyncio.sleep(0.1)
                
                # Step 3: Executor - å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å­ä»»åŠ¡
                focus_preview = ', '.join([s.focus[:20] for s in subtasks[:3]]) + ('...' if len(subtasks) > 3 else '')
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'searching', 'message': f'æ£€ç´¢ä¿¡æ¯ ({len(subtasks)} ä¸ªæ–¹å‘)', 'detail': f'æ­£åœ¨å¹¶è¡Œæ£€ç´¢ï¼š{focus_preview}'})}\n\n"
                await asyncio.sleep(0.1)
                
                executor = Executor(model, max_parallel=len(subtasks))
                
                # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å­ä»»åŠ¡ - ä½¿ç”¨æ™ºèƒ½å¹¶å‘æ§åˆ¶
                import asyncio as aio
                import time
                from .tools.concurrency_manager import run_concurrent_tasks
                
                parallel_start = time.time()
                print(f"[DEBUG] Starting intelligent parallel execution of {len(subtasks)} subtasks...")
                
                # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
                tasks = [executor.execute_single(subtask) for subtask in subtasks]
                
                # ä½¿ç”¨æ™ºèƒ½å¹¶å‘æ§åˆ¶æ‰§è¡Œ
                results = await run_concurrent_tasks(tasks)
                
                parallel_end = time.time()
                print(f"[DEBUG] Intelligent parallel execution completed: {parallel_end - parallel_start:.2f}s")
                
                # è¿‡æ»¤æœ‰æ•ˆç»“æœ
                subtask_results = [r for r in results if r is not None and not isinstance(r, Exception)]
                
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'searching', 'message': f'æ£€ç´¢å®Œæˆ ({len(subtask_results)}/{len(subtasks)})', 'detail': f'å·²è·å– {len(subtask_results)} ä¸ªç ”ç©¶æ–¹å‘çš„ä¿¡æ¯'})}\n\n"
                await asyncio.sleep(0.1)
                
                if not subtask_results:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'æ£€ç´¢å¤±è´¥ï¼Œæœªè·å–åˆ°ç»“æœ'})}\n\n"
                    return
                
                # Step 4: Synthesizer
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'synthesizing', 'message': 'æ•´åˆåˆ†æç»“æœ', 'detail': f'æ­£åœ¨ç»¼åˆåˆ†æ {len(subtask_results)} ä¸ªç ”ç©¶æ–¹å‘çš„ä¿¡æ¯ï¼Œç”Ÿæˆç ”ç©¶æŠ¥å‘Š'})}\n\n"
                await asyncio.sleep(0.1)
                
                # #region debug log - before synthesize
                import json as json_lib
                import time
                log_path = "/Users/fl/Desktop/my_code/clarifyagent/.cursor/debug.log"
                try:
                    with open(log_path, "a", encoding="utf-8") as f:
                        f.write(json_lib.dumps({"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A,B,C,D,E", "location": "web.py:before_synthesize", "message": "About to call synthesize_results", "data": {"num_subtask_results": len(subtask_results), "goal": plan.task.goal, "research_focus": plan.task.research_focus}, "timestamp": time.time() * 1000}, ensure_ascii=False) + "\n")
                except Exception as e:
                    print(f"[DEBUG] Failed to write log in web.py: {e}")
                # #endregion
                
                research_result = await synthesize_results(
                    model,
                    plan.task.goal,
                    plan.task.research_focus,
                    subtask_results
                )
                
                yield f"data: {json.dumps({'type': 'progress', 'stage': 'complete', 'message': 'ç ”ç©¶å®Œæˆ', 'detail': 'ç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ'})}\n\n"
                await asyncio.sleep(0.1)
                
                add_assistant(state, f"ç ”ç©¶å®Œæˆï¼š{research_result.goal}")
                update_task_draft(state, plan.task.model_dump())
                save_research_result(state, render_research_result(research_result))  # ä¿å­˜ç ”ç©¶ç»“æœä»¥ä¾¿åç»­å¯¹è¯
                yield f"data: {json.dumps({'type': 'result', 'response_type': 'research_result', 'message': 'ç ”ç©¶å®Œæˆï¼', 'research_result': render_research_result(research_result)})}\n\n"
                
            except Exception as e:
                logger.exception(f"Research error: {e}")
                yield f"data: {json.dumps({'type': 'error', 'message': f'ç ”ç©¶æ‰§è¡Œå‡ºé”™: {str(e)}'})}\n\n"
        
        else:
            yield f"data: {json.dumps({'type': 'error', 'message': f'æœªå¤„ç†çš„çŠ¶æ€: {plan.next_action}'})}\n\n"
    
    except Exception as e:
        logger.exception(f"Error in stream: {e}")
        yield f"data: {json.dumps({'type': 'error', 'message': f'å¤„ç†å‡ºé”™: {str(e)}'})}\n\n"
    
    finally:
        yield "data: {\"type\": \"done\"}\n\n"


async def handle_simple_chat(state: SessionState, message: str) -> str:
    """å¤„ç†ç®€å•çš„åç»­å¯¹è¯"""
    # ä½¿ç”¨ç®€å•çš„Agentè¿›è¡Œå¯¹è¯
    from .agent import build_model
    
    model = build_model("fast")
    
    # æ„å»ºä¸Šä¸‹æ–‡ï¼šæœ€è¿‘å‡ è½®å¯¹è¯ + ç ”ç©¶ç»“æœæ‘˜è¦
    context_messages = state.messages[-6:]  # æœ€è¿‘3è½®å¯¹è¯
    
    context = "åŸºäºä¹‹å‰çš„ç ”ç©¶ï¼š\n"
    if state.last_research_result.get("synthesis"):
        context += state.last_research_result["synthesis"][:500] + "...\n\n"
    
    context += "æœ€è¿‘å¯¹è¯ï¼š\n"
    for msg in context_messages:
        role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
        context += f"{role}: {msg['content'][:200]}\n"
    
    prompt = f"""
ä½œä¸ºç ”ç©¶åŠ©æ‰‹ï¼ŒåŸºäºä¸Šè¿°ç ”ç©¶å†…å®¹å’Œå¯¹è¯å†å²ï¼Œç®€æ´å›ç­”ç”¨æˆ·çš„åç»­é—®é¢˜ï¼š

{message}

è¦æ±‚ï¼š
- ç›´æ¥å›ç­”ï¼Œä¸éœ€è¦é‡æ–°ç ”ç©¶
- åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œåˆ†æ
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯´æ˜éœ€è¦æ–°çš„ç ”ç©¶
- ä¿æŒç®€æ´ï¼Œ1-3æ®µè½å³å¯
"""
    
    try:
        # Use Anthropic API directly
        response = await model.acompletion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"å¯¹è¯å‡ºé”™ï¼š{str(e)}"


@app.get("/api/chat/stream")
async def chat_stream(session_id: str = "new", message: str = ""):
    """Stream chat responses with progress updates."""
    return StreamingResponse(
        stream_generator(session_id, message),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, debug=True)
